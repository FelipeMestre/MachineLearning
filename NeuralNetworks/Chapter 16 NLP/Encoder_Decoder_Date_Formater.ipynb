{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615027bc",
   "metadata": {},
   "source": [
    "Train an encoder–decoder model that can convert a date string from one format to another (e.g., from “April 22, 2019” to “2019-04-22”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f98174",
   "metadata": {},
   "source": [
    "First step is to be able to generate a train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa139b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 29, 8270\n",
      "2019-04-22\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "months_days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "def is_leap_year(year):\n",
    "    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "\n",
    "def generate_date_string():\n",
    "    year = np.random.randint(1000, 9999)\n",
    "    month = np.random.randint(1, 13)  # 1-12\n",
    "    max_day = months_days[month-1]\n",
    "    if month == 2 and is_leap_year(year):\n",
    "        max_day = 29\n",
    "    day = np.random.randint(1, max_day + 1)\n",
    "    return f\"{months[month-1]} {day}, {year}\"\n",
    "\n",
    "def generate_label_string(date_string):\n",
    "    date_parts = date_string.split(\" \")\n",
    "    month, day, year = date_parts[0], date_parts[1], date_parts[2]\n",
    "    day_numeric = int(day.replace(\",\", \"\"))\n",
    "    month_numeric = months.index(month) + 1\n",
    "    return f\"{year}-{month_numeric:02d}-{day_numeric:02d}\"\n",
    "\n",
    "print(generate_date_string())\n",
    "print(generate_label_string(\"April 22, 2019\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20ec6398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '-': 11}\n",
      "{'<PAD>': 0, ' ': 1, ',': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, 'A': 13, 'D': 14, 'F': 15, 'J': 16, 'M': 17, 'N': 18, 'O': 19, 'S': 20, 'a': 21, 'b': 22, 'c': 23, 'e': 24, 'g': 25, 'h': 26, 'i': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'r': 33, 's': 34, 't': 35, 'u': 36, 'v': 37, 'y': 38}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "input_chars = \"\".join(sorted(set(\"\".join(months) + \"0123456789, \")))\n",
    "output_chars = \"0123456789-\"\n",
    "input_vocab = { \n",
    "    '<PAD>': 0 #Padding character\n",
    "}\n",
    "\n",
    "for char in input_chars:\n",
    "    input_vocab[char] = len(input_vocab)\n",
    "\n",
    "output_vocab = {\n",
    "    '<PAD>': 0,\n",
    "}\n",
    "\n",
    "for char in output_chars:\n",
    "    output_vocab[char] = len(output_vocab)\n",
    "\n",
    "print(output_vocab)\n",
    "print(input_vocab)\n",
    "\n",
    "input_vocab_size = len(input_vocab)\n",
    "output_vocab_size = len(output_vocab)\n",
    "id_to_input_char = {idx: char for char, idx in input_vocab.items()}\n",
    "id_to_output_char = {idx: char for char, idx in output_vocab.items()}\n",
    "\n",
    "def ids_to_string(sequence, id_to_char, pad_id=0):\n",
    "    flat_sequence = np.asarray(sequence).flatten()\n",
    "    return ''.join(\n",
    "        id_to_char.get(int(idx), '')\n",
    "        for idx in flat_sequence\n",
    "        if int(idx) != pad_id\n",
    "    )\n",
    "\n",
    "def convert_string_to_id(string, vocab: dict) -> list[int]:\n",
    "    return [vocab[char] for char in string]\n",
    "        \n",
    "def generate_label(date_string):\n",
    "    return generate_label_string(date_string)\n",
    "\n",
    "def generate_sample():\n",
    "    date_string = generate_date_string()\n",
    "    label = generate_label(date_string)\n",
    "    tokenized_date = convert_string_to_id(date_string, input_vocab)\n",
    "    tokenized_label = convert_string_to_id(label, output_vocab)\n",
    "    return tokenized_date, tokenized_label\n",
    "\n",
    "def generate_dataset(\n",
    "    num_samples: int = 10000\n",
    ") -> tf.data.Dataset:\n",
    "    \n",
    "    values = []\n",
    "    labels = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        value, label = generate_sample()\n",
    "        values.append(value)\n",
    "        labels.append(label)\n",
    "\n",
    "    values = tf.ragged.constant(values, dtype=tf.int32, ragged_rank=1)\n",
    "    labels = tf.ragged.constant(labels, dtype=tf.int32, ragged_rank=1)\n",
    "\n",
    "    values = (values).to_tensor()\n",
    "    labels = (labels).to_tensor()\n",
    "    \n",
    "    return values, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28ffc8",
   "metadata": {},
   "source": [
    "There are some problems with working with this strings. The numeric ones are easy, but i struggled when working with the word April or month words. How can i do that?\n",
    "\n",
    "Important, dont forget about SAS and EOS tokens, and sequence max lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3207d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = generate_dataset(10000)\n",
    "validation_x, validation_y = generate_dataset(2000)\n",
    "test_x, test_y = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d82bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 1768-08-27\n",
      "Input: August 27, 1768\n",
      "---\n",
      "\n",
      "Output: 6557-08-15\n",
      "Input: August 15, 6557\n",
      "---\n",
      "\n",
      "Output: 1196-05-04\n",
      "Input: May 4, 1196\n",
      "---\n",
      "\n",
      "Output: 2389-04-07\n",
      "Input: April 7, 2389\n",
      "---\n",
      "\n",
      "Output: 3990-11-14\n",
      "Input: November 14, 3990\n",
      "---\n",
      "\n",
      "Output: 7253-10-05\n",
      "Input: October 5, 7253\n",
      "---\n",
      "\n",
      "Output: 5667-08-19\n",
      "Input: August 19, 5667\n",
      "---\n",
      "\n",
      "Output: 7205-01-19\n",
      "Input: January 19, 7205\n",
      "---\n",
      "\n",
      "Output: 7988-12-07\n",
      "Input: December 7, 7988\n",
      "---\n",
      "\n",
      "Output: 2992-11-28\n",
      "Input: November 28, 2992\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(10):\n",
    "    x_batch, y_batch = generate_sample()\n",
    "    converted = ids_to_string(y_batch, id_to_output_char)\n",
    "    converted_x = ids_to_string(x_batch, id_to_input_char)\n",
    "    print(\"Output: \" + converted)\n",
    "    print(\"Input: \" + converted_x)\n",
    "    print(\"---\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6effe758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Versión simple: solo input → output\n",
    "embedding_size = 32\n",
    "max_length_output = train_y.shape[1]\n",
    "print(max_length_output)\n",
    "padding_char_sum_constant = 1\n",
    "\n",
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=input_vocab_size,\n",
    "        output_dim=embedding_size, \n",
    "        input_shape=[None]\n",
    "    ),\n",
    "    tf.keras.layers.LSTM(128)  # without return_sequences, generates a vector\n",
    "])\n",
    "\n",
    "decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.RepeatVector(max_length_output),  # repeat the vector N times\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(output_vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    decoder\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83003da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 12s 34ms/step - loss: 1.7311 - accuracy: 0.3739 - val_loss: 1.2887 - val_accuracy: 0.5292\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 8s 27ms/step - loss: 1.1218 - accuracy: 0.5954 - val_loss: 0.9515 - val_accuracy: 0.6587\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.8355 - accuracy: 0.6929 - val_loss: 0.7337 - val_accuracy: 0.7250\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 10s 30ms/step - loss: 0.6345 - accuracy: 0.7582 - val_loss: 0.5657 - val_accuracy: 0.7792\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.4681 - accuracy: 0.8147 - val_loss: 0.4211 - val_accuracy: 0.8335\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3579 - accuracy: 0.8609 - val_loss: 0.3044 - val_accuracy: 0.8815\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.2247 - accuracy: 0.9212 - val_loss: 0.1869 - val_accuracy: 0.9395\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.1368 - accuracy: 0.9607 - val_loss: 0.1112 - val_accuracy: 0.9714\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.0863 - accuracy: 0.9802 - val_loss: 0.0654 - val_accuracy: 0.9873\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.1394 - accuracy: 0.9648 - val_loss: 0.0633 - val_accuracy: 0.9895\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0434 - accuracy: 0.9932 - val_loss: 0.0359 - val_accuracy: 0.9952\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0266 - accuracy: 0.9968 - val_loss: 0.0242 - val_accuracy: 0.9973\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.0185 - accuracy: 0.9985 - val_loss: 0.0184 - val_accuracy: 0.9982\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.0133 - accuracy: 0.9992 - val_loss: 0.0137 - val_accuracy: 0.9987\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.0098 - accuracy: 0.9996 - val_loss: 0.0107 - val_accuracy: 0.9991\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 0.0084 - val_accuracy: 0.9994\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.0226 - accuracy: 0.9953 - val_loss: 0.0085 - val_accuracy: 0.9993\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.0052 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9995\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9997\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x34476dfc0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=20, validation_data=(validation_x, validation_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad548112",
   "metadata": {},
   "source": [
    "The first issue i noticed is that when generating the dates, in order to get every position to have the same meaning i should generate the output dates like 2025-12-02 not 2025-12-2, this is a way of making meaning regular and output length always the same.\n",
    "\n",
    "It was difficult to add padding to the strings. The input and output vocabs should have a char '<PAD>' used to represent empty spaces in the chains due to the fact that not of them have the same length. And we must feed the model with a (batch, input_vocab_size, max_length_string)\n",
    "\n",
    "That adds one char to the possible values of input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40d73bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: May 3, 1290\n",
      "Expected: 1290-05-03\n",
      "Predicted: 1290-05-03\n"
     ]
    }
   ],
   "source": [
    "def predict_date(date_string, model, max_input_len=18, max_output_len=10):\n",
    "    tokenized = convert_string_to_id(date_string, input_vocab)\n",
    "\n",
    "    input_tensor = np.zeros((1, max_input_len), dtype=np.int32)\n",
    "    input_tensor[0, :len(tokenized)] = tokenized\n",
    "\n",
    "    probs = model.predict(input_tensor, verbose=0)[0]  # [T_out, vocab]\n",
    "    indices = np.argmax(probs, axis=-1)\n",
    "\n",
    "    decoded = ids_to_string(indices, id_to_output_char, pad_id=0)\n",
    "    return decoded.strip()\n",
    "\n",
    "# Uso:\n",
    "test = \"May 3, 1290\"\n",
    "predicted = predict_date(test, model)\n",
    "print(f\"Input: {test}\")\n",
    "print(f\"Expected: {generate_label(test)}\")\n",
    "print(f\"Predicted: {predicted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88dfe7c",
   "metadata": {},
   "source": [
    "So now that i have created a correct LSTM, lets use teacher forcing to improve the performance and speed up training. \n",
    "\n",
    "Teacher forcing consists in passing the word that the decoder should have output in the previous step regardless of what it actually outputs. For the first word, the decoder is given a <SOS> token and it is expected to end the sequence with an <EOF> token. \n",
    "\n",
    "It feeds the decoder the ground-truth token from the previous timestep instead of its own prediction, which speeds up and stabilizes training because gradients propagate through the correct context, exposes the model to valid target sequences at every step, preventing it from wandering into impossible states, breaks the chain of accumulated errors that would otherwise arise when an early mistake pollutes all subsequent inputs; and optimizes the exact conditional relationships the loss compares, so that at inference the decoder can switch to autoregressive mode having already learned how each true token leads to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee802098",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_input_vocab = {\n",
    "    '<PAD>': 0,\n",
    "    '<SOS>': 1,\n",
    "    '<EOS>': 2,\n",
    "}\n",
    "\n",
    "teacher_forcing_output_vocab = {\n",
    "    '<PAD>': 0,\n",
    "    '<SOS>': 1,\n",
    "    '<EOS>': 2,\n",
    "}\n",
    "\n",
    "for char in input_chars:\n",
    "    teacher_forcing_input_vocab[char] = len(teacher_forcing_input_vocab)\n",
    "\n",
    "for char in output_chars:\n",
    "    teacher_forcing_output_vocab[char] = len(teacher_forcing_output_vocab)\n",
    "\n",
    "teacher_forcing_input_vocab_size = len(teacher_forcing_input_vocab)\n",
    "teacher_forcing_output_vocab_size = len(teacher_forcing_output_vocab)\n",
    "teacher_forcing_id_to_input_char = {idx: char for char, idx in teacher_forcing_input_vocab.items()}\n",
    "teacher_forcing_id_to_output_char = {idx: char for char, idx in teacher_forcing_output_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89fe608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_teacher_forcing_sample():\n",
    "    date_string = generate_date_string()\n",
    "    label = generate_label(date_string)\n",
    "    tokenized_date = convert_string_to_id(date_string, teacher_forcing_input_vocab)\n",
    "    tokenized_label = convert_string_to_id(label, teacher_forcing_output_vocab)\n",
    "    return tokenized_date, tokenized_label\n",
    "\n",
    "def generate_teacher_forcing_dataset(size: int):\n",
    "    encoder_inputs = []\n",
    "    decoder_inputs = []\n",
    "    decoder_outputs = []\n",
    "    \n",
    "    for _ in range(size):\n",
    "        value, label = generate_teacher_forcing_sample()\n",
    "        decoder_in = [teacher_forcing_output_vocab['<SOS>']] + label\n",
    "        decoder_out = label + [teacher_forcing_output_vocab['<EOS>']]\n",
    "\n",
    "        encoder_inputs.append(value)\n",
    "        decoder_inputs.append(decoder_in)\n",
    "        decoder_outputs.append(decoder_out)\n",
    "\n",
    "    encoder_inputs = tf.ragged.constant(encoder_inputs, dtype=tf.int32, ragged_rank=1)\n",
    "    decoder_inputs = tf.ragged.constant(decoder_inputs, dtype=tf.int32, ragged_rank=1)\n",
    "    decoder_outputs = tf.ragged.constant(decoder_outputs, dtype=tf.int32, ragged_rank=1)\n",
    "\n",
    "    encoder_inputs = (encoder_inputs).to_tensor()\n",
    "    decoder_inputs = (decoder_inputs).to_tensor()\n",
    "    decoder_outputs = (decoder_outputs).to_tensor()\n",
    "    \n",
    "    return encoder_inputs, decoder_inputs, decoder_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "703fc635",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_train, decoder_inputs_train, decoder_outputs_train = generate_teacher_forcing_dataset(10000)\n",
    "encoder_inputs_valid, decoder_inputs_valid, decoder_outputs_valid = generate_teacher_forcing_dataset(2000)\n",
    "encoder_inputs_test, decoder_inputs_test, decoder_outputs_test = generate_teacher_forcing_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b41cf190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 18])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc5cdbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18,), dtype=int32, numpy=\n",
       "array([20, 33, 39, 26, 31, 24, 26, 35,  3,  6,  5,  4,  3, 14, 13, 14,  5,\n",
       "        0], dtype=int32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41012825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11,), dtype=int32, numpy=array([ 1, 12, 11, 12,  3, 13,  4,  4, 13,  4,  3], dtype=int32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9c92fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11,), dtype=int32, numpy=array([12, 11, 12,  3, 13,  4,  4, 13,  4,  3,  2], dtype=int32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfaae8e",
   "metadata": {},
   "source": [
    "The decoder input starts with the id 1 (SOS) character and the output with id 2 character (EOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56718b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_14 (Embedding)    (None, None, 32)             1312      ['input_13[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)    (None, None, 32)             448       ['input_14[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_16 (LSTM)              [(None, 128),                82432     ['embedding_14[0][0]']        \n",
      "                              (None, 128),                                                        \n",
      "                              (None, 128)]                                                        \n",
      "                                                                                                  \n",
      " lstm_17 (LSTM)              (None, None, 128)            82432     ['embedding_15[0][0]',        \n",
      "                                                                     'lstm_16[0][1]',             \n",
      "                                                                     'lstm_16[0][2]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, None, 14)             1806      ['lstm_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 168430 (657.93 KB)\n",
      "Trainable params: 168430 (657.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "\n",
    "encoder_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=teacher_forcing_input_vocab_size,\n",
    "    output_dim=embedding_size,\n",
    "    input_shape=[None]\n",
    ")(encoder_inputs)\n",
    "\n",
    "encoder_lstm_output, encoder_state_h, encoder_state_c = tf.keras.layers.LSTM(128, return_state=True)(encoder_embedding)\n",
    "decoder_initial_state = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=teacher_forcing_output_vocab_size,\n",
    "    output_dim=embedding_size,\n",
    "    input_shape=[None]\n",
    ")(decoder_inputs)\n",
    "\n",
    "decoder_lstm_output = tf.keras.layers.LSTM(128, return_sequences=True)(decoder_embedding, initial_state=decoder_initial_state)\n",
    "\n",
    "decoder_dense = tf.keras.layers.Dense(teacher_forcing_output_vocab_size, activation='softmax')(decoder_lstm_output)\n",
    "\n",
    "teacher_forcing_model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_dense)\n",
    "\n",
    "teacher_forcing_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "de662974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 10s 28ms/step - loss: 1.6095 - accuracy: 0.4034 - val_loss: 1.3373 - val_accuracy: 0.4728\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 1.1282 - accuracy: 0.5817 - val_loss: 0.8440 - val_accuracy: 0.7072\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.6052 - accuracy: 0.7947 - val_loss: 0.3588 - val_accuracy: 0.8951\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2240 - accuracy: 0.9440 - val_loss: 0.1283 - val_accuracy: 0.9787\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0778 - accuracy: 0.9910 - val_loss: 0.0514 - val_accuracy: 0.9959\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.0367 - accuracy: 0.9979 - val_loss: 0.0267 - val_accuracy: 0.9989\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.0198 - accuracy: 0.9996 - val_loss: 0.0165 - val_accuracy: 0.9996\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.0161 - accuracy: 0.9988 - val_loss: 0.0091 - val_accuracy: 0.9999\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9999\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0225 - accuracy: 0.9949 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 8.3816e-04 - accuracy: 1.0000 - val_loss: 8.9520e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 6.9151e-04 - accuracy: 1.0000 - val_loss: 7.5895e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 5.7726e-04 - accuracy: 1.0000 - val_loss: 6.5423e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3610a7640>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_forcing_model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "teacher_forcing_model.fit([encoder_inputs_train, decoder_inputs_train], decoder_outputs_train, epochs=20, validation_data=([encoder_inputs_valid, decoder_inputs_valid], decoder_outputs_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccbffab",
   "metadata": {},
   "source": [
    "It performed better acquiring 92% of accuracy in just 3 epochs, much better than the previous model. Now let`s make some predictions, instead of predicting one sentence at a time, the new model outputs one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "625415ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1290-01-30\n"
     ]
    }
   ],
   "source": [
    "def predict_date(date_string, model, max_input_len=18, max_output_len=10):\n",
    "    tokenized = convert_string_to_id(date_string, teacher_forcing_input_vocab)\n",
    "\n",
    "    encoder_input = np.zeros((1, max_input_len), dtype=np.int32)\n",
    "    encoder_input[0, :len(tokenized)] = tokenized\n",
    "\n",
    "    decoder_tokens = [teacher_forcing_output_vocab['<SOS>']] #Dimension batch and first token\n",
    "\n",
    "    output_ids = []\n",
    "    for _ in range(max_output_len):\n",
    "        decoder_input = np.zeros((1, len(decoder_tokens)), dtype=np.int32)\n",
    "        decoder_input[0, :] = decoder_tokens\n",
    "\n",
    "        probs = model.predict([encoder_input, decoder_input], verbose=0)\n",
    "\n",
    "        next_char_idx = np.argmax(probs[0, -1])\n",
    "        next_char = ids_to_string([next_char_idx], id_to_output_char, pad_id=0)\n",
    "\n",
    "        output_ids.append(next_char_idx)\n",
    "        decoder_tokens = decoder_tokens + [next_char_idx]\n",
    "\n",
    "        if next_char == '<EOS>':\n",
    "            break\n",
    "\n",
    "    return ids_to_string(output_ids, teacher_forcing_id_to_output_char).strip()\n",
    "\n",
    "predicted = predict_date(\"January 30, 1290\", teacher_forcing_model)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5dac5",
   "metadata": {},
   "source": [
    "Obviously, my first attempt to predict with the new model failed. It kept on an on predicting and never stopped. First i was not updating the decoders input on every time.\n",
    "\n",
    "I also found these bugs in the way\n",
    "\n",
    "Generated targets with the old output vocabulary, then wrapped those IDs with <SOS>/<EOS> from a brand-new vocabulary, and finally tried to decode the predictions with the new dictionary. Unsurprisingly, the model “learned” to emit what it was fed—numbers in the old ID space—but I interpreted them as the new tokens, so everything looked like <SOS> and <EOS>. I fixed it by regenerating the teacher-forcing dataset using a single, consistent teacher_forcing_output_vocab: every digit and the hyphen gets re-encoded in that dictionary before I add the special tokens, so the IDs I train on and the IDs I decode are exactly the same.\n",
    "\n",
    "The second issue was my inference loop. I kept resetting decoder_input to a single timestep, meaning the LSTM saw only <SOS> (or just the last character) and had no memory of the prefix it was supposed to condition on, causing endless repeats. The fix was to maintain the full prefix in a decoder_tokens list. On each iteration I rebuild the tensor (1, len(decoder_tokens)), call model.predict([encoder_input, decoder_input]), grab only the logits from the final timestep (probs[0, -1]), choose that next ID, append it to both the output list and decoder_tokens, and stop when <EOS> appears or the max length is reached. Once both the vocabulary alignment and the autoregressive loop were corrected, the teacher-forcing model started producing accurate date conversions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
