{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f310209e",
   "metadata": {},
   "source": [
    "Embedded Reber grammars were used by Hochreiter and Schmidhuber in their paper about LSTMs. They are artificial grammars that produce strings such as “BPBTSXXVPSEPE”. Check out Jenny Orr’s nice introduction to this topic, then choose a particular embedded Reber grammar (such as the one represented on Orr’s page), then train an RNN to identify whether a string respects that grammar or not. You will first need to write a function capable of generating a training batch containing about 50% strings that respect the grammar, and 50% that don’t."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f146889",
   "metadata": {},
   "source": [
    "First i wrote the algorithm using three classes to represent the graph and the random next step choice. Without the embedded option, just simple phrases. And the method to validate algorithmically a sequence. Now i have the capability of generating valid sentences. Lets try to generate wrong ones randomly, but in order to the model to learn all the rules i must include the right mistakes in the sentences such as:\n",
    "\n",
    "- Wrong char: Switch a random wrong char in a random position\n",
    "- Invalid Transition: In order to the model to understand the state a wrong transition can be generated \n",
    "- Incomplete sequences: The model must acknoledge the correct ending of the sequence\n",
    "- Extra chars: The model must recognize a wrong end of sequence\n",
    "- Permutation: Change the order of correct sub-sequences making the model understand the order logic\n",
    "\n",
    "I have a background in object oriented programming so i made it in classes. Now that i can create wrong and right sentences. I must prepare a dataset to train my model.\n",
    "\n",
    "I was lazy so i asked the ia if it could generate me a class to generate a dataset leveraging TensorFlow Dataset API, it made a quite good job, maybe too much for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e8bd09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset classes\n",
    "\n",
    "from random import randint, choice\n",
    "\n",
    "\n",
    "class ReberGraph:\n",
    "    def __init__(self, embedded=False):\n",
    "        self.embedded = embedded\n",
    "        self.result_string = ''\n",
    "        self.initial_node = ReberNode()\n",
    "        second_node = ReberNode()\n",
    "        third_node = ReberNode()\n",
    "        fourth_node = ReberNode()\n",
    "        fifth_node = ReberNode()\n",
    "        sixth_node = ReberNode()\n",
    "        seventh_node = ReberNode()\n",
    "        final_node = ReberNode(is_terminal=True)\n",
    "\n",
    "        self.initial_node.add_connection(ReberConnection(self.initial_node, second_node, 'B'))\n",
    "        \n",
    "        second_node.add_connection(ReberConnection(second_node, third_node, 'T'))        \n",
    "        second_node.add_connection(ReberConnection(second_node, fourth_node, 'P'))\n",
    "        \n",
    "        third_node.add_connection(ReberConnection(third_node, third_node, 'S'))\n",
    "        third_node.add_connection(ReberConnection(third_node, fifth_node, 'X'))\n",
    "\n",
    "        fourth_node.add_connection(ReberConnection(fourth_node, sixth_node, 'V'))\n",
    "        fourth_node.add_connection(ReberConnection(fourth_node, fourth_node, 'T'))\n",
    "\n",
    "        fifth_node.add_connection(ReberConnection(fifth_node, fourth_node, 'X'))\n",
    "        fifth_node.add_connection(ReberConnection(fifth_node, seventh_node, 'S'))\n",
    "\n",
    "        sixth_node.add_connection(ReberConnection(sixth_node, fifth_node, 'V'))\n",
    "        sixth_node.add_connection(ReberConnection(sixth_node, seventh_node, 'P'))\n",
    "\n",
    "        seventh_node.add_connection(ReberConnection(seventh_node, final_node, 'E'))\n",
    "        \n",
    "        self.error_strategies = []\n",
    "\n",
    "    def set_error_strategies(self, strategies):\n",
    "        self.error_strategies = strategies\n",
    "\n",
    "    def generate_sequence(self):\n",
    "        sequence = ''\n",
    "        current_node = self.initial_node\n",
    "        while not current_node.is_terminal:\n",
    "            selected_connection_index = randint(0, len(current_node.connections) - 1)\n",
    "            sequence += current_node.connections[selected_connection_index].label\n",
    "            current_node = current_node.connections[selected_connection_index].node_to\n",
    "        \n",
    "        return sequence   \n",
    "\n",
    "    def validate_sequence(self, sequence):\n",
    "        current_node = self.initial_node\n",
    "        for char in sequence:\n",
    "            found = False\n",
    "            for connection in current_node.connections:\n",
    "                if connection.label == char:\n",
    "                    current_node = connection.node_to\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                return False\n",
    "        return current_node.is_terminal\n",
    "\n",
    "    def generate_wrong_sequence(self):\n",
    "        selected_strategy = choice(self.error_strategies)\n",
    "        return selected_strategy.generate_error(self)\n",
    "\n",
    "        \n",
    "class ReberConnection:\n",
    "    def __init__(self, node_from, node_to, label):\n",
    "        self.node_from = node_from\n",
    "        self.node_to = node_to\n",
    "        self.label = label\n",
    "\n",
    "class ReberNode:\n",
    "    def __init__(self, is_terminal=False):\n",
    "        self.is_terminal = is_terminal\n",
    "        self.connections = []\n",
    "\n",
    "    def add_connection(self, connection):\n",
    "        self.connections.append(connection)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28a7ef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPVVSE\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "reber_graph = ReberGraph()\n",
    "sequence = reber_graph.generate_sequence()\n",
    "print(sequence)\n",
    "print(reber_graph.validate_sequence(sequence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6934e7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Strategy Interface and Implementations\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from random import randint, choice\n",
    "\n",
    "\n",
    "class SequenceErrorStrategy(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_error(self, graph):\n",
    "        pass\n",
    "\n",
    "\n",
    "class WrongCharError(SequenceErrorStrategy):    \n",
    "    \n",
    "    def generate_error(self, graph):\n",
    "        sequence = graph.generate_sequence()\n",
    "        if len(sequence) == 0:\n",
    "            return sequence\n",
    "        \n",
    "        invalid_chars = ['Z', 'Q', 'W', 'R', 'Y', 'U', 'I', 'O', 'A', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N']\n",
    "        random_pos = randint(0, len(sequence) - 1)\n",
    "        wrong_char = choice(invalid_chars)\n",
    "        \n",
    "        return sequence[:random_pos] + wrong_char + sequence[random_pos + 1:]\n",
    "\n",
    "\n",
    "class InvalidTransitionError(SequenceErrorStrategy):\n",
    "\n",
    "    def generate_error(self, graph):\n",
    "        sequence = ''\n",
    "        current_node = graph.initial_node\n",
    "        valid_labels = {'B', 'T', 'P', 'S', 'X', 'V', 'E'}\n",
    "        \n",
    "        steps_before_error = randint(1, 3)\n",
    "        step_count = 0\n",
    "        \n",
    "        while not current_node.is_terminal and len(sequence) < 15:\n",
    "            step_count += 1\n",
    "            \n",
    "            if step_count == steps_before_error:\n",
    "                # Get valid labels that are NOT in the current connections\n",
    "                available_labels = {c.label for c in current_node.connections}\n",
    "                invalid_labels = list(valid_labels - available_labels)\n",
    "                \n",
    "                if invalid_labels:\n",
    "                    # Insert a valid character but not allowed in this state\n",
    "                    wrong_label = choice(invalid_labels)\n",
    "                    sequence += wrong_label\n",
    "                    break  # Terminate because it's already invalid\n",
    "                else:\n",
    "                    # If all labels are valid, use a random one from the available ones\n",
    "                    selected_connection_index = randint(0, len(current_node.connections) - 1)\n",
    "                    sequence += current_node.connections[selected_connection_index].label\n",
    "                    current_node = current_node.connections[selected_connection_index].node_to\n",
    "            else:\n",
    "                # Continue normally\n",
    "                selected_connection_index = randint(0, len(current_node.connections) - 1)\n",
    "                sequence += current_node.connections[selected_connection_index].label\n",
    "                current_node = current_node.connections[selected_connection_index].node_to\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "\n",
    "class IncompleteSequenceError(SequenceErrorStrategy):\n",
    "    \n",
    "    def generate_error(self, graph):\n",
    "        sequence = ''\n",
    "        current_node = graph.initial_node\n",
    "        # Stop after a random number of steps (but before completing)\n",
    "        max_steps = randint(2, 6)\n",
    "        step_count = 0\n",
    "        \n",
    "        while not current_node.is_terminal and step_count < max_steps:\n",
    "            if len(current_node.connections) == 0:\n",
    "                break\n",
    "            selected_connection_index = randint(0, len(current_node.connections) - 1)\n",
    "            sequence += current_node.connections[selected_connection_index].label\n",
    "            current_node = current_node.connections[selected_connection_index].node_to\n",
    "            step_count += 1\n",
    "        \n",
    "        # The sequence does not end in 'E', therefore it's invalid\n",
    "        return sequence\n",
    "\n",
    "\n",
    "class ExtraCharsError(SequenceErrorStrategy):\n",
    "    \"\"\"Strategy: Add extra characters after the valid end of the sequence\"\"\"\n",
    "    \n",
    "    def generate_error(self, graph):\n",
    "        sequence = graph.generate_sequence()\n",
    "        # Add extra characters after the final 'E'\n",
    "        extra_chars = ['X', 'S', 'T', 'P', 'V']\n",
    "        num_extra = randint(1, 4)\n",
    "        \n",
    "        for _ in range(num_extra):\n",
    "            sequence += choice(extra_chars)\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "\n",
    "class PermutationError(SequenceErrorStrategy):    \n",
    "    def generate_error(self, graph):\n",
    "        sequence = list(graph.generate_sequence())\n",
    "        if len(sequence) >= 2:\n",
    "            pos = randint(0, len(sequence) - 2)\n",
    "            sequence[pos], sequence[pos + 1] = sequence[pos + 1], sequence[pos]\n",
    "        return ''.join(sequence)\n",
    "\n",
    "\n",
    "class WrongStartError(SequenceErrorStrategy):    \n",
    "    def generate_error(self, graph):\n",
    "        invalid_starts = ['T', 'P', 'S', 'X', 'V', 'E']\n",
    "        sequence = choice(invalid_starts)\n",
    "        \n",
    "        current_node = graph.initial_node\n",
    "        while not current_node.is_terminal:\n",
    "            selected_connection_index = randint(0, len(current_node.connections) - 1)\n",
    "            sequence += current_node.connections[selected_connection_index].label\n",
    "            current_node = current_node.connections[selected_connection_index].node_to\n",
    "        \n",
    "        return sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18d160b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Valid sequences ===\n",
      "Valid 1: BPTVPE (validation: True)\n",
      "Valid 2: BTXXVPE (validation: True)\n",
      "Valid 3: BPTTTTTTTTVVSE (validation: True)\n",
      "\n",
      "=== Invalid sequences ===\n",
      "Invalid 1: TBXSE (validation: False)\n",
      "Invalid 2: BPVVVXPE (validation: False)\n",
      "Invalid 3: BS (validation: False)\n",
      "Invalid 4: BPE (validation: False)\n",
      "Invalid 5: BTSDSE (validation: False)\n"
     ]
    }
   ],
   "source": [
    "# Usage example: Configure and test error strategies\n",
    "\n",
    "error_strategies = [\n",
    "    WrongCharError(),\n",
    "    InvalidTransitionError(),\n",
    "    IncompleteSequenceError(),\n",
    "    ExtraCharsError(),\n",
    "    PermutationError(),\n",
    "    WrongStartError()\n",
    "]\n",
    "\n",
    "reber_graph.set_error_strategies(error_strategies)\n",
    "\n",
    "print(\"=== Valid sequences ===\")\n",
    "for i in range(3):\n",
    "    valid_seq = reber_graph.generate_sequence()\n",
    "    print(f\"Valid {i+1}: {valid_seq} (validation: {reber_graph.validate_sequence(valid_seq)})\")\n",
    "\n",
    "print(\"\\n=== Invalid sequences ===\")\n",
    "for i in range(5):\n",
    "    wrong_seq = reber_graph.generate_wrong_sequence()\n",
    "    print(f\"Invalid {i+1}: {wrong_seq} (validation: {reber_graph.validate_sequence(wrong_seq)})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b37919dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "\n",
    "class ReberDataset:\n",
    "    def __init__(self, graph: ReberGraph, vocab: Optional[dict] = None):\n",
    "        \"\"\"\n",
    "        Initialize the ReberDataset generator.\n",
    "        \n",
    "        Args:\n",
    "            graph: ReberGraph instance for generating sequences\n",
    "            vocab: Optional vocabulary mapping. If None, will be created from Reber alphabet\n",
    "        \"\"\"\n",
    "        self.graph = graph\n",
    "        self.reber_alphabet = ['B', 'T', 'P', 'S', 'X', 'V', 'E']\n",
    "        \n",
    "        # Create vocabulary mapping: char -> int\n",
    "        if vocab is None:\n",
    "            self.vocab = {char: idx + 1 for idx, char in enumerate(self.reber_alphabet)}\n",
    "            self.vocab['<PAD>'] = 0  # Padding token\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "        \n",
    "        # Reverse vocabulary: int -> char\n",
    "        self.idx_to_char = {idx: char for char, idx in self.vocab.items()}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "    \n",
    "    def _sequence_to_indices(self, sequence: str) -> list:\n",
    "        \"\"\"Convert a sequence string to a list of token indices\"\"\"\n",
    "        return [self.vocab.get(char, 0) for char in sequence]\n",
    "    \n",
    "    def _generate_sample(self, is_valid: bool) -> Tuple[list, int]:\n",
    "        \"\"\"\n",
    "        Generate a single sample (sequence, label).\n",
    "        \n",
    "        Args:\n",
    "            is_valid: True for valid sequence, False for invalid\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (tokenized_sequence, label)\n",
    "        \"\"\"\n",
    "        if is_valid:\n",
    "            sequence = self.graph.generate_sequence()\n",
    "            label = 1\n",
    "        else:\n",
    "            sequence = self.graph.generate_wrong_sequence()\n",
    "            label = 0\n",
    "        \n",
    "        tokenized = self._sequence_to_indices(sequence)\n",
    "        return tokenized, label\n",
    "    \n",
    "    def _generator(self, num_samples: int, valid_ratio: float = 0.5):\n",
    "        \"\"\"\n",
    "        Generator function for creating sequences on-the-fly.\n",
    "        This enables lazy loading and memory efficiency.\n",
    "        \n",
    "        Args:\n",
    "            num_samples: Total number of samples to generate\n",
    "            valid_ratio: Ratio of valid sequences (default 0.5 for 50/50 split)\n",
    "        \"\"\"\n",
    "        num_valid = int(num_samples * valid_ratio)\n",
    "        num_invalid = num_samples - num_valid\n",
    "        \n",
    "        # Generate valid sequences\n",
    "        for _ in range(num_valid):\n",
    "            tokenized, label = self._generate_sample(is_valid=True)\n",
    "            yield (np.array(tokenized, dtype=np.int32), np.array(label, dtype=np.int32))\n",
    "        \n",
    "        # Generate invalid sequences\n",
    "        for _ in range(num_invalid):\n",
    "            tokenized, label = self._generate_sample(is_valid=False)\n",
    "            yield (np.array(tokenized, dtype=np.int32), np.array(label, dtype=np.int32))\n",
    "    \n",
    "    def generate_dataset(\n",
    "        self,\n",
    "        num_samples: int = 10000,\n",
    "        batch_size: int = 32,\n",
    "        valid_ratio: float = 0.5,\n",
    "        max_length: Optional[int] = None,\n",
    "        shuffle: bool = True,\n",
    "        shuffle_buffer_size: int = 1000,\n",
    "        prefetch: bool = True,\n",
    "        prefetch_size: int = tf.data.AUTOTUNE,\n",
    "        cache: bool = False,\n",
    "        repeat: bool = False,\n",
    "        num_parallel_calls: int = tf.data.AUTOTUNE\n",
    "    ) -> tf.data.Dataset:\n",
    "        \"\"\"\n",
    "        Generate a TensorFlow Dataset with all optimizations.\n",
    "        \n",
    "        Args:\n",
    "            num_samples: Total number of samples to generate\n",
    "            batch_size: Batch size for training\n",
    "            valid_ratio: Ratio of valid sequences (default 0.5)\n",
    "            max_length: Maximum sequence length for padding. If None, uses max in batch\n",
    "            shuffle: Whether to shuffle the dataset\n",
    "            shuffle_buffer_size: Buffer size for shuffling\n",
    "            prefetch: Whether to prefetch batches for better GPU utilization\n",
    "            prefetch_size: Number of batches to prefetch (AUTOTUNE recommended)\n",
    "            cache: Whether to cache the dataset in memory (useful for small datasets)\n",
    "            repeat: Whether to repeat the dataset indefinitely (for training loops)\n",
    "            num_parallel_calls: Number of parallel calls for map operations\n",
    "            \n",
    "        Returns:\n",
    "            tf.data.Dataset ready for training\n",
    "        \"\"\"\n",
    "        # Create dataset from generator\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            lambda: self._generator(num_samples, valid_ratio),\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32),  # Variable length sequences\n",
    "                tf.TensorSpec(shape=(), dtype=tf.int32)  # Labels\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Shuffle if requested\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(\n",
    "                buffer_size=shuffle_buffer_size,\n",
    "                reshuffle_each_iteration=True\n",
    "            )\n",
    "        \n",
    "        # Pad sequences to the same length within each batch\n",
    "        # This is more efficient than padding to a fixed max_length\n",
    "        dataset = dataset.padded_batch(\n",
    "            batch_size=batch_size,\n",
    "            padded_shapes=(\n",
    "                [max_length] if max_length else [None],  # Pad sequences\n",
    "                []  # Labels don't need padding\n",
    "            ),\n",
    "            padding_values=(\n",
    "                self.vocab['<PAD>'],  # Padding value for sequences\n",
    "                0  # Padding value for labels (won't be used)\n",
    "            ),\n",
    "            drop_remainder=False  # Keep last incomplete batch\n",
    "        )\n",
    "        \n",
    "        # Cache if requested (useful for small datasets that fit in memory)\n",
    "        if cache:\n",
    "            dataset = dataset.cache()\n",
    "        \n",
    "        # Prefetch for better GPU utilization\n",
    "        if prefetch:\n",
    "            dataset = dataset.prefetch(prefetch_size)\n",
    "        \n",
    "        # Repeat if requested (for training loops)\n",
    "        if repeat:\n",
    "            dataset = dataset.repeat()\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def generate_train_val_split(\n",
    "        self,\n",
    "        num_samples: int = 10000,\n",
    "        val_ratio: float = 0.2,\n",
    "        batch_size: int = 32,\n",
    "        **kwargs\n",
    "    ) -> Tuple[tf.data.Dataset, tf.data.Dataset]:\n",
    "        \"\"\"\n",
    "        Generate training and validation datasets with proper splitting.\n",
    "        \n",
    "        Args:\n",
    "            num_samples: Total number of samples\n",
    "            val_ratio: Ratio of validation samples\n",
    "            batch_size: Batch size\n",
    "            **kwargs: Additional arguments passed to generate_dataset\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (train_dataset, val_dataset)\n",
    "        \"\"\"\n",
    "        num_train = int(num_samples * (1 - val_ratio))\n",
    "        num_val = num_samples - num_train\n",
    "        \n",
    "        train_dataset = self.generate_dataset(\n",
    "            num_samples=num_train,\n",
    "            batch_size=batch_size,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        val_dataset = self.generate_dataset(\n",
    "            num_samples=num_val,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,  # Don't shuffle validation set\n",
    "            cache=True,  # Cache validation set for faster evaluation\n",
    "            **{k: v for k, v in kwargs.items() if k not in ['shuffle', 'cache']}\n",
    "        )\n",
    "        \n",
    "        return train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b66c92f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "Vocabulary size: 8\n",
      "Vocabulary: {'B': 1, 'T': 2, 'P': 3, 'S': 4, 'X': 5, 'V': 6, 'E': 7, '<PAD>': 0}\n",
      "\n",
      "Sample batch:\n",
      "Sequences shape: (32, 22)\n",
      "Labels shape: (32,)\n",
      "First sequence: [1 2 4 4 5 4 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "First label: 1\n",
      "Decoded sequence: BTSSXSE\n"
     ]
    }
   ],
   "source": [
    "# Example: Using the TensorFlow Dataset\n",
    "\n",
    "# Initialize the dataset generator\n",
    "dataset_generator = ReberDataset(reber_graph)\n",
    "\n",
    "# Generate a dataset with all optimizations\n",
    "train_dataset = dataset_generator.generate_dataset(\n",
    "    num_samples=10000,\n",
    "    batch_size=32,\n",
    "    valid_ratio=0.5,\n",
    "    shuffle=True,\n",
    "    prefetch=True,\n",
    "    cache=False  # Set to True if dataset fits in memory\n",
    ")\n",
    "\n",
    "# Or generate train/val split directly\n",
    "train_ds, val_ds = dataset_generator.generate_train_val_split(\n",
    "    num_samples=10000,\n",
    "    val_ratio=0.2,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Inspect the dataset\n",
    "print(\"Dataset structure:\")\n",
    "print(f\"Vocabulary size: {dataset_generator.vocab_size}\")\n",
    "print(f\"Vocabulary: {dataset_generator.vocab}\")\n",
    "print(\"\\nSample batch:\")\n",
    "for sequences, labels in train_dataset.take(1):\n",
    "    print(f\"Sequences shape: {sequences.shape}\")  # (batch_size, max_seq_length)\n",
    "    print(f\"Labels shape: {labels.shape}\")      # (batch_size,)\n",
    "    print(f\"First sequence: {sequences[0].numpy()}\")\n",
    "    print(f\"First label: {labels[0].numpy()}\")\n",
    "    print(f\"Decoded sequence: {''.join([dataset_generator.idx_to_char.get(int(idx), '?') for idx in sequences[0].numpy() if idx != 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffaf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using with Keras Model (commented out - uncomment to use)\n",
    "\n",
    "# # Create train/validation datasets\n",
    "# train_ds, val_ds = dataset_generator.generate_train_val_split(\n",
    "#     num_samples=10000,\n",
    "#     val_ratio=0.2,\n",
    "#     batch_size=32\n",
    "# )\n",
    "\n",
    "# # Example model architecture\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(\n",
    "#         input_dim=dataset_generator.vocab_size,\n",
    "#         output_dim=64,\n",
    "#         mask_zero=True  # Automatically mask padding tokens\n",
    "#     ),\n",
    "#     tf.keras.layers.LSTM(64, return_sequences=False),\n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# # The dataset is already batched, shuffled, and prefetched!\n",
    "# history = model.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=10,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "print(\"Dataset ready for training! Uncomment the code above to train a model.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
